{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nanu\\Anaconda3-1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_union\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "\n",
    "\n",
    "# Experimenting with two types of ngrams, one being a 1, 1 and another being 1, 4\n",
    "wordVectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30000)\n",
    "\n",
    "charVectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    ngram_range=(1, 4),\n",
    "    max_features=30000)\n",
    "\n",
    "multiVectorizer = make_union(wordVectorizer, charVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nanu\\Anaconda3-1\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "categories = list(train.columns.values)[2:]\n",
    "barPlotData = {}\n",
    "\n",
    "for category in categories: \n",
    "    barPlotData[category] = train[train[category]==1].count()\n",
    "    \n",
    "barPlotDF = pd.DataFrame(data=barPlotData)\n",
    "sns.set(font_scale = 2)\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.barplot(data=barPlotDF)\n",
    "ax.axes.set_title(\"Toxic Comment Classification Data\",fontsize= 20)\n",
    "ax.set_xlabel(\"Categories\",fontsize=15)\n",
    "ax.set_ylabel(\"Number of Comments\",fontsize=15)\n",
    "ax.tick_params(labelsize=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153164 entries, 0 to 153163\n",
      "Data columns (total 2 columns):\n",
      "id              153164 non-null object\n",
      "comment_text    153164 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNonToxic(row): \n",
    "    if (row['threat'] or row['toxic'] or row['severe_toxic'] or row['obscene'] or row['insult'] or row['identity_hate']):\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "    \n",
    "def removeEverythingExceptWords(comment): \n",
    "    return re.sub('\\W+',' ', comment)\n",
    "\n",
    "def tokenizeAndLemmatize(comment):\n",
    "    tokens = word_tokenize(comment)\n",
    "    return [ lemmatizer.lemmatize(w) for w in tokens ]\n",
    "\n",
    "def removeStopWords(comment_tokens):\n",
    "    # Method to remove stop words from the comment \n",
    "    # Input argument: The comment_tokens after tokenizing the comment\n",
    "    return ' '.join([w for w in comment_tokens if not w in stop_words])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(label, prediction):\n",
    "    true_positives = 0.0\n",
    "    false_positives = 0.0\n",
    "    true_negatives = 0.0\n",
    "    false_negatives = 0.0\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        if ((label[i] == 0.0) and (prediction[i] == 0.0)):\n",
    "            true_positives += 1.0\n",
    "        elif ((label[i] == 1.0) and (prediction[i] == 1.0)): \n",
    "            true_negatives += 1.0\n",
    "        elif ((label[i] == 0.0) and (prediction[i] == 1.0)):\n",
    "            false_negatives += 1.0\n",
    "        elif ((label[i] == 1.0) and (prediction[i] == 0.0)):\n",
    "            false_positives += 1.0\n",
    "    \n",
    "    return (true_positives, true_negatives, false_positives, false_negatives)\n",
    "\n",
    "def compute_evaluation_metrics(label, prediction):\n",
    "    (true_positives, true_negatives, false_positives, false_negatives) = compute_confusion_matrix(label, prediction)\n",
    "    accuracy = accuracy_score(label, prediction)\n",
    "    precision = precision_score(label, prediction, average='micro')\n",
    "    recall = recall_score(label, prediction, average='micro')\n",
    "    f1score = f1_score(label, prediction, average='micro')\n",
    "    return (accuracy, precision, recall, f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = train\n",
    "trainingData['nonToxic'] = trainingData.apply(lambda row: isNonToxic(row), axis = 1)\n",
    "trainingData['parsedComments'] = trainingData.apply(lambda row: removeEverythingExceptWords(row['comment_text']), axis = 1)\n",
    "trainingData['tokenizedComments'] = trainingData.apply(lambda row: tokenizeAndLemmatize(row['parsedComments']), axis = 1)\n",
    "trainingData['noStopWordComments'] = trainingData.apply(lambda row: removeStopWords(row['tokenizedComments']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>nonToxic</th>\n",
       "      <th>parsedComments</th>\n",
       "      <th>tokenizedComments</th>\n",
       "      <th>noStopWordComments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>[COCKSUCKER, BEFORE, YOU, PISS, AROUND, ON, MY...</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey what is it talk What is it an exclusive gr...</td>\n",
       "      <td>[Hey, what, is, it, talk, What, is, it, an, ex...</td>\n",
       "      <td>Hey talk What exclusive group WP TALIBANS good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bye Don t look come or think of comming back T...</td>\n",
       "      <td>[Bye, Don, t, look, come, or, think, of, commi...</td>\n",
       "      <td>Bye Don look come think comming back Tosser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You are gay or antisemmitian Archangel WHite T...</td>\n",
       "      <td>[You, are, gay, or, antisemmitian, Archangel, ...</td>\n",
       "      <td>You gay antisemmitian Archangel WHite Tiger Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS DRY</td>\n",
       "      <td>[FUCK, YOUR, FILTHY, MOTHER, IN, THE, ASS, DRY]</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS DRY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  nonToxic  \\\n",
       "6       1             1        1       0       1              0         0   \n",
       "12      1             0        0       0       0              0         0   \n",
       "16      1             0        0       0       0              0         0   \n",
       "42      1             0        1       0       1              1         0   \n",
       "43      1             0        1       0       1              0         0   \n",
       "\n",
       "                                       parsedComments  \\\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  Hey what is it talk What is it an exclusive gr...   \n",
       "16  Bye Don t look come or think of comming back T...   \n",
       "42  You are gay or antisemmitian Archangel WHite T...   \n",
       "43            FUCK YOUR FILTHY MOTHER IN THE ASS DRY    \n",
       "\n",
       "                                    tokenizedComments  \\\n",
       "6   [COCKSUCKER, BEFORE, YOU, PISS, AROUND, ON, MY...   \n",
       "12  [Hey, what, is, it, talk, What, is, it, an, ex...   \n",
       "16  [Bye, Don, t, look, come, or, think, of, commi...   \n",
       "42  [You, are, gay, or, antisemmitian, Archangel, ...   \n",
       "43    [FUCK, YOUR, FILTHY, MOTHER, IN, THE, ASS, DRY]   \n",
       "\n",
       "                                   noStopWordComments  \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  \n",
       "12  Hey talk What exclusive group WP TALIBANS good...  \n",
       "16        Bye Don look come think comming back Tosser  \n",
       "42  You gay antisemmitian Archangel WHite Tiger Me...  \n",
       "43             FUCK YOUR FILTHY MOTHER IN THE ASS DRY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[trainingData['nonToxic'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTotal, testTotal = train_test_split(trainingData, random_state=42, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the noStopWordComments from the data frames to perform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(trainTotal['noStopWordComments'] )\n",
    "vectorizer.fit(testTotal['noStopWordComments'])\n",
    "trainX_tfidf = vectorizer.transform((trainTotal['noStopWordComments'])) \n",
    "testX_tfidf = vectorizer.transform((testTotal['noStopWordComments']))\n",
    "\n",
    "multiVectorizer.fit(trainTotal['noStopWordComments'])\n",
    "multiVectorizer.fit(testTotal['noStopWordComments'])\n",
    "\n",
    "trainX_multi_tfidf = multiVectorizer.transform((trainTotal['noStopWordComments'])) \n",
    "testX_multi_tfidf = multiVectorizer.transform((testTotal['noStopWordComments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.9345964237967914%, precision is 0.9345964237967914, recall is 0.9345964237967914, and f1 score is 0.9345964237967914\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.9899732620320856%, precision is 0.9899732620320856, recall is 0.9899732620320856, and f1 score is 0.9899732620320856\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.9625459558823529%, precision is 0.9625459558823529, recall is 0.9625459558823529, and f1 score is 0.9625459558823529\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.9971590909090909%, precision is 0.9971590909090909, recall is 0.9971590909090909, and f1 score is 0.9971590909090909\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.9587232620320856%, precision is 0.9587232620320856, recall is 0.9587232620320856, and f1 score is 0.9587232620320856\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.9911639371657754%, precision is 0.9911639371657754, recall is 0.9911639371657754, and f1 score is 0.9911639371657754\n",
      "\n",
      "\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier with one vectorizer. \n",
    "logisticRegressionPipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='lbfgs'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    logisticRegressionPipeline.fit(trainX_tfidf, trainTotal[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = logisticRegressionPipeline.predict(testX_tfidf)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.9616268382352942%, precision is 0.9616268382352942, recall is 0.9616268382352942, and f1 score is 0.961626838235294\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.990704378342246%, precision is 0.990704378342246, recall is 0.990704378342246, and f1 score is 0.990704378342246\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.9792780748663101%, precision is 0.9792780748663101, recall is 0.9792780748663101, and f1 score is 0.9792780748663101\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.9974933155080213%, precision is 0.9974933155080213, recall is 0.9974933155080213, and f1 score is 0.9974933155080213\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.9719878008021391%, precision is 0.9719878008021391, recall is 0.9719878008021391, and f1 score is 0.9719878008021391\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.9923128342245989%, precision is 0.9923128342245989, recall is 0.9923128342245989, and f1 score is 0.9923128342245989\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WARNING: DO NOT RUN\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier with multi vectorizer. \n",
    "logisticRegressionPipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='lbfgs'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    logisticRegressionPipeline.fit(trainX_multi_tfidf, trainTotal[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = logisticRegressionPipeline.predict(testX_multi_tfidf)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.9477565173796791%, precision is 0.9477565173796791, recall is 0.9477565173796791, and f1 score is 0.9477565173796791\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.9901612633689839%, precision is 0.9901612633689839, recall is 0.9901612633689839, and f1 score is 0.9901612633689839\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.9707344585561497%, precision is 0.9707344585561497, recall is 0.9707344585561497, and f1 score is 0.9707344585561497\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.9972635360962567%, precision is 0.9972635360962567, recall is 0.9972635360962567, and f1 score is 0.9972635360962567\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.9625877339572193%, precision is 0.9625877339572193, recall is 0.9625877339572193, and f1 score is 0.9625877339572193\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.9912892713903744%, precision is 0.9912892713903744, recall is 0.9912892713903744, and f1 score is 0.9912892713903744\n",
      "\n",
      "\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "supportVectorMachinePipeline = Pipeline([\n",
    "        ('svm', OneVsRestClassifier(LinearSVC(random_state=0), n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    # Training SVM on train data\n",
    "    supportVectorMachinePipeline.fit(trainX_tfidf, trainTotal[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = supportVectorMachinePipeline.predict(testX_tfidf)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try ensembling the models to get a clearer view on the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nanu\\Anaconda3-1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.9243816844919787%, precision is 0.9243816844919787, recall is 0.9243816844919787, and f1 score is 0.9243816844919787\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.9892003676470589%, precision is 0.9892003676470589, recall is 0.9892003676470589, and f1 score is 0.9892003676470589\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.9567805815508021%, precision is 0.9567805815508021, recall is 0.9567805815508021, and f1 score is 0.9567805815508021\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.9971173128342246%, precision is 0.9971173128342246, recall is 0.9971173128342246, and f1 score is 0.9971173128342246\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.9569268048128342%, precision is 0.9569268048128342, recall is 0.9569268048128342, and f1 score is 0.9569268048128342\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.9909132687165776%, precision is 0.9909132687165776, recall is 0.9909132687165776, and f1 score is 0.9909132687165776\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=2)\n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    # Training SVM on train data\n",
    "    clf.fit(trainX_tfidf, trainTotal[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = clf.predict(testX_tfidf)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.908944685828877%, precision is 0.908944685828877, recall is 0.908944685828877, and f1 score is 0.908944685828877\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.9898479278074866%, precision is 0.9898479278074866, recall is 0.9898479278074866, and f1 score is 0.9898479278074866\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.9477774064171123%, precision is 0.9477774064171123, recall is 0.9477774064171123, and f1 score is 0.9477774064171123\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.9971590909090909%, precision is 0.9971590909090909, recall is 0.9971590909090909, and f1 score is 0.9971590909090909\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.9503885360962567%, precision is 0.9503885360962567, recall is 0.9503885360962567, and f1 score is 0.9503885360962567\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.990975935828877%, precision is 0.990975935828877, recall is 0.990975935828877, and f1 score is 0.990975935828877\n",
      "\n",
      "\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "naiveBayesPipeline = Pipeline([\n",
    "        ('nb', OneVsRestClassifier(MultinomialNB(), n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    # Training SVM on train data\n",
    "    naiveBayesPipeline.fit(trainX_tfidf, trainTotal[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = naiveBayesPipeline.predict(testX_tfidf)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider this as a binary classification problem, we have a label called nonToxic comments, which can help us treat this multilabel problem as a binary classification one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (One vs. One) Test accuracy is 0.8983330548128342%, precision is 0.8983330548128342, recall is 0.8983330548128342, and f1 score is 0.8983330548128342\n",
      "\n",
      "\n",
      "SVM (One vs. One) Test accuracy is 0.9462942847593583%, precision is 0.9462942847593583, recall is 0.9462942847593583, and f1 score is 0.9462942847593583\n",
      "\n",
      "\n",
      "Logistic Regression (One vs. One) Test accuracy is 0.9315466243315508%, precision is 0.9315466243315508, recall is 0.9315466243315508, and f1 score is 0.9315466243315508\n",
      "\n",
      "\n",
      "Random Forest (One vs. One) Test accuracy is 0.9053517713903744%, precision is 0.9053517713903744, recall is 0.9053517713903744, and f1 score is 0.9053517713903744\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "nbOneVsOnePipeline = Pipeline([('nb', OneVsOneClassifier(MultinomialNB(), n_jobs=-1)),])\n",
    "\n",
    "svmOneVsOnePipeline = Pipeline([('svm', OneVsOneClassifier(LinearSVC(random_state=0), n_jobs=-1)),])\n",
    "\n",
    "logisticRegressionOneVsOnePipeline = Pipeline([('clf', OneVsOneClassifier(LogisticRegression(solver='lbfgs'), n_jobs=-1)),])\n",
    "\n",
    "randomForestOneVsOne = RandomForestClassifier(n_estimators=2)\n",
    "\n",
    "\n",
    "nbOneVsOnePipeline.fit(trainX_tfidf, trainTotal['nonToxic'])\n",
    "svmOneVsOnePipeline.fit(trainX_tfidf, trainTotal['nonToxic'])\n",
    "logisticRegressionOneVsOnePipeline.fit(trainX_tfidf, trainTotal['nonToxic'])\n",
    "randomForestOneVsOne.fit(trainX_tfidf, trainTotal['nonToxic'])\n",
    "\n",
    "\n",
    "nbPred = nbOneVsOnePipeline.predict(testX_tfidf)\n",
    "svmPred = svmOneVsOnePipeline.predict(testX_tfidf)\n",
    "lrPred = logisticRegressionOneVsOnePipeline.predict(testX_tfidf)\n",
    "rfPred = randomForestOneVsOne.predict(testX_tfidf)\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal['nonToxic']).values, nbPred)\n",
    "print('Naive Bayes (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal['nonToxic']).values, svmPred)\n",
    "print('SVM (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal['nonToxic']).values, lrPred)\n",
    "print('Logistic Regression (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((testTotal['nonToxic']).values, rfPred)\n",
    "print('Random Forest (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been evaluating only the training and test models that we derived from the training set. Now it's time to check the performance on the actual test set which we have from the dataset. However, we need to transform the test set in the same way we did the trainingData. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['parsedComments'] = testData.apply(lambda row: removeEverythingExceptWords(row['comment_text']), axis = 1)\n",
    "testData['tokenizedComments'] = testData.apply(lambda row: tokenizeAndLemmatize(row['parsedComments']), axis = 1)\n",
    "testData['noStopWordComments'] = testData.apply(lambda row: removeStopWords(row['tokenizedComments']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.fit(testData['noStopWordComments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_tfidf_actual = vectorizer.transform(testData['noStopWordComments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels['nonToxic'] = test_labels.apply(lambda row: isNonToxic(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47872, 2582084)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2582084)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_tfidf_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (One vs. One) Test accuracy is 0.3769488913843984%, precision is 0.3769488913843984, recall is 0.3769488913843984, and f1 score is 0.3769488913843984\n",
      "\n",
      "\n",
      "SVM (One vs. One) Test accuracy is 0.5277415058368807%, precision is 0.5277415058368807, recall is 0.5277415058368807, and f1 score is 0.5277415058368807\n",
      "\n",
      "\n",
      "Logistic Regression (One vs. One) Test accuracy is 0.49854404429239246%, precision is 0.49854404429239246, recall is 0.49854404429239246, and f1 score is 0.49854404429239246\n",
      "\n",
      "\n",
      "Random Forest (One vs. One) Test accuracy is 0.5205531325899037%, precision is 0.5205531325899037, recall is 0.5205531325899037, and f1 score is 0.5205531325899037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating each model on the test set now: \n",
    "\n",
    "metricsDF = pd.DataFrame()\n",
    "\n",
    "nbPred = nbOneVsOnePipeline.predict(testX_tfidf_actual)\n",
    "svmPred = svmOneVsOnePipeline.predict(testX_tfidf_actual)\n",
    "lrPred = logisticRegressionOneVsOnePipeline.predict(testX_tfidf_actual)\n",
    "rfPred = randomForestOneVsOne.predict(testX_tfidf_actual)\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels['nonToxic']).values, nbPred)\n",
    "print('Naive Bayes (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels['nonToxic']).values, svmPred)\n",
    "print('SVM (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels['nonToxic']).values, lrPred)\n",
    "print('Logistic Regression (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "\n",
    "(accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels['nonToxic']).values, rfPred)\n",
    "print('Random Forest (One vs. One) Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try predicting the per label class on the actual test set from the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Testing on toxic comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.3779478206367031%, precision is 0.3779478206367031, recall is 0.3779478206367031, and f1 score is 0.3779478206367031\n",
      "\n",
      "\n",
      "**Testing on severe_toxic comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.4153129978323888%, precision is 0.4153129978323888, recall is 0.4153129978323888, and f1 score is 0.4153129978323888\n",
      "\n",
      "\n",
      "**Testing on obscene comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.3936107701548667%, precision is 0.3936107701548667, recall is 0.3936107701548667, and f1 score is 0.3936107701548667\n",
      "\n",
      "\n",
      "**Testing on threat comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.41633151393277795%, precision is 0.41633151393277795, recall is 0.41633151393277795, and f1 score is 0.41633151393277795\n",
      "\n",
      "\n",
      "**Testing on insult comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.39533441278629444%, precision is 0.39533441278629444, recall is 0.39533441278629444, and f1 score is 0.39533441278629444\n",
      "\n",
      "\n",
      "**Testing on identity_hate comments.. with Naive Bayes Pipeline.**\n",
      "Test accuracy is 0.4130605103026821%, precision is 0.4130605103026821, recall is 0.4130605103026821, and f1 score is 0.4130605103026821\n",
      "\n",
      "\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for category in categories:\n",
    "    print('**Testing on {} comments.. with Naive Bayes Pipeline.**'.format(category))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = naiveBayesPipeline.predict(testX_tfidf_actual)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Testing on toxic comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.37773889425713614%, precision is 0.37773889425713614, recall is 0.37773889425713614, and f1 score is 0.37773889425713614\n",
      "\n",
      "\n",
      "**Testing on severe_toxic comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.41463398709879606%, precision is 0.41463398709879606, recall is 0.41463398709879606, and f1 score is 0.41463398709879606\n",
      "\n",
      "\n",
      "**Testing on obscene comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.3933626700791309%, precision is 0.3933626700791309, recall is 0.3933626700791309, and f1 score is 0.39336267007913084\n",
      "\n",
      "\n",
      "**Testing on threat comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.4155741558068476%, precision is 0.4155741558068476, recall is 0.4155741558068476, and f1 score is 0.4155741558068476\n",
      "\n",
      "\n",
      "**Testing on insult comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.3950471390143898%, precision is 0.3950471390143898, recall is 0.3950471390143898, and f1 score is 0.39504713901438976\n",
      "\n",
      "\n",
      "**Testing on identity_hate comments with Random Forest Classifier...**\n",
      "Test accuracy is 0.4124990206575958%, precision is 0.4124990206575958, recall is 0.4124990206575958, and f1 score is 0.4124990206575958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for category in categories:\n",
    "    print('**Testing on {} comments with Random Forest Classifier...**'.format(category))\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = clf.predict(testX_tfidf_actual)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Learning on toxic comments...**\n",
      "Test accuracy is 0.379018568331984%, precision is 0.379018568331984, recall is 0.379018568331984, and f1 score is 0.379018568331984\n",
      "\n",
      "\n",
      "**Learning on severe_toxic comments...**\n",
      "Test accuracy is 0.41411167114987857%, precision is 0.41411167114987857, recall is 0.41411167114987857, and f1 score is 0.41411167114987857\n",
      "\n",
      "\n",
      "**Learning on obscene comments...**\n",
      "Test accuracy is 0.39395027552166306%, precision is 0.39395027552166306, recall is 0.39395027552166306, and f1 score is 0.39395027552166306\n",
      "\n",
      "\n",
      "**Learning on threat comments...**\n",
      "Test accuracy is 0.41462092920007315%, precision is 0.41462092920007315, recall is 0.41462092920007315, and f1 score is 0.4146209292000731\n",
      "\n",
      "\n",
      "**Learning on insult comments...**\n",
      "Test accuracy is 0.3959220182288266%, precision is 0.3959220182288266, recall is 0.3959220182288266, and f1 score is 0.3959220182288266\n",
      "\n",
      "\n",
      "**Learning on identity_hate comments...**\n",
      "Test accuracy is 0.413713405238829%, precision is 0.413713405238829, recall is 0.413713405238829, and f1 score is 0.413713405238829\n",
      "\n",
      "\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for category in categories:\n",
    "    print('**Learning on {} comments...**'.format(category))\n",
    "    \n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = supportVectorMachinePipeline.predict(testX_tfidf_actual)\n",
    "    (accuracy, precision, recall, f1score) = compute_evaluation_metrics((test_labels[category]).values, prediction)\n",
    "    print('Test accuracy is {}%, precision is {}, recall is {}, and f1 score is {}'.format(accuracy, precision, recall, f1score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
